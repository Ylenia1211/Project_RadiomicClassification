{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codeCNR_classificazione con VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcQZSUS0bc8V"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.stats import norm\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from tensorflow.keras import layers\n",
        "import operator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwBbVI3lebLe"
      },
      "source": [
        "#Creazione Modello VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb5fXnCJdYGk",
        "outputId": "76bc968b-ff7d-48af-aad7-68a61b7c03be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.keras.metrics import Accuracy as accuracy\n",
        "from tensorflow.keras.metrics import Precision as precision\n",
        "\n",
        "\n",
        "#https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "\n",
        "original_dim = 108 #feature 108\n",
        "intermediate_dim = 500\n",
        "latent_dim = 2\n",
        "\n",
        "inputs = keras.Input(shape=(original_dim,))\n",
        "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
        "z_mean = layers.Dense(latent_dim)(h)\n",
        "z_log_sigma = layers.Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=0.1)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
        "#print(z)\n",
        "# Create encoder: un codificatore che mappa gli input allo spazio latente\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "encoder.summary()\n",
        "# Create decoder: un generatore che pu√≤ prendere punti sullo spazio latente e e restituisce i campioni ricostruiti corrispondenti.\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
        "\n",
        "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "\n",
        "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam') \n",
        "vae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 108)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500)          54500       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            1002        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            1002        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2)            0           dense_8[0][0]                    \n",
            "                                                                 dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 56,504\n",
            "Trainable params: 56,504\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 500)               1500      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 108)               54108     \n",
            "=================================================================\n",
            "Total params: 55,608\n",
            "Trainable params: 55,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"vae_mlp\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 108)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            [(None, 2), (None, 2 56504       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, 108)          55608       encoder[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Minimum_1 (TensorFl [(None, 108)]        0           decoder[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Maximum_1 (TensorFl [(None, 108)]        0           tf_op_layer_Minimum_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_5 (TensorFlowOp [(None, 108)]        0           tf_op_layer_Maximum_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_5 (TensorFlow [(None, 108)]        0           tf_op_layer_Maximum_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_6 (TensorFlow [(None, 108)]        0           tf_op_layer_Sub_5[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500)          54500       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Log_2 (TensorFlowOp [(None, 108)]        0           tf_op_layer_AddV2_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlowOp [(None, 108)]        0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Log_3 (TensorFlowOp [(None, 108)]        0           tf_op_layer_AddV2_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            1002        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            1002        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_4 (TensorFlowOp [(None, 108)]        0           input_2[0][0]                    \n",
            "                                                                 tf_op_layer_Log_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_5 (TensorFlowOp [(None, 108)]        0           tf_op_layer_Sub_4[0][0]          \n",
            "                                                                 tf_op_layer_Log_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_8 (TensorFlow [(None, 2)]          0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_1 (TensorFlo [(None, 2)]          0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_7 (TensorFlow [(None, 108)]        0           tf_op_layer_Mul_4[0][0]          \n",
            "                                                                 tf_op_layer_Mul_5[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_6 (TensorFlowOp [(None, 2)]          0           tf_op_layer_AddV2_8[0][0]        \n",
            "                                                                 tf_op_layer_Square_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_1 (TensorFlowOp [(None, 2)]          0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Neg_1 (TensorFlowOp [(None, 108)]        0           tf_op_layer_AddV2_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sub_7 (TensorFlowOp [(None, 2)]          0           tf_op_layer_Sub_6[0][0]          \n",
            "                                                                 tf_op_layer_Exp_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_2 (TensorFlowO [(None,)]            0           tf_op_layer_Neg_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum_1 (TensorFlowOp [(None,)]            0           tf_op_layer_Sub_7[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_6 (TensorFlowOp [(None,)]            0           tf_op_layer_Mean_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_7 (TensorFlowOp [(None,)]            0           tf_op_layer_Sum_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_9 (TensorFlow [(None,)]            0           tf_op_layer_Mul_6[0][0]          \n",
            "                                                                 tf_op_layer_Mul_7[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_3 (TensorFlowO [()]                 0           tf_op_layer_AddV2_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_loss_1 (AddLoss)            ()                   0           tf_op_layer_Mean_3[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 112,112\n",
            "Trainable params: 112,112\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDCo5t6VhICk",
        "outputId": "ac31638e-78a6-4c49-bb9e-14272ebd6278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#https://www.datacamp.com/community/tutorials/autoencoder-classifier-python\n",
        "num_classes = 2\n",
        "def fc(enco):\n",
        "    flat = Flatten()(enco)\n",
        "    den = Dense(200, activation='relu')(flat)\n",
        "    out = Dense(num_classes, activation='softmax')(den)\n",
        "    return out\n",
        "\n",
        "encode = encoder(inputs)[2]\n",
        "print(encode)\n",
        "full_model = Model(inputs,fc(encode))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"encoder/lambda_1/add_1:0\", shape=(None, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXE9WhHBbq_2"
      },
      "source": [
        "'''\n",
        "Funzione per fare oversampling solo sul training (nella fase di K-fold split)\n",
        "@return oversampling sui campioni, oversampling sulle etichette (status)\n",
        "'''\n",
        "def oversampling_training(dataset_training, y_status, y_tipology):\n",
        "  y_status = pd.Series(y_status)\n",
        "  y_tipology = pd.Series(y_tipology)   \n",
        "  data = {\"STATUS\": y_status, \"Tipologia\": y_tipology} \n",
        "  data_class = pd.concat(data, axis = 1) \n",
        "  print(\"Numero di Sample per Status:\")\n",
        "  print(y_status.value_counts())\n",
        "\n",
        "  tuple_class = list(map(tuple, data_class.to_numpy()))\n",
        "  #print(len(tuple_class))  #45 sample\n",
        "  encode_tuple = { (0,0) : 1, (0,1) : 2, (0,2) : 3, (1,0) : 4, (1,1) : 5, (1,2) : 6}\n",
        "  macro_class = []\n",
        "  for couple in tuple_class: \n",
        "    macro_class.append(encode_tuple[couple])\n",
        "\n",
        "  series_macro_class = pd.Series((v for v in macro_class) )\n",
        "\n",
        "  #print(\"NUMERO DI TUPLE PER CLASSE MACRO:\")\n",
        "  print(series_macro_class.value_counts())\n",
        "\n",
        "   # Oversampling \"NORMALE\" sullo STATUS\n",
        "  oversample = SMOTE(k_neighbors=1)    \n",
        "  data_objs_oversampling, macro_class_oversampling = oversample.fit_resample(dataset_training, y_status)\n",
        "  \n",
        " \n",
        "  # Oversampling NORMALE sulle Tipologie   ( problema: troppo pochi esempi per la classe '3')\n",
        "  '''\n",
        "  oversample = SMOTE(k_neighbors=1)     #Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3\n",
        "  data_objs_oversampling, macro_class_oversampling = oversample.fit_resample(dataset_training, series_macro_class)\n",
        "  '''\n",
        "\n",
        " \n",
        "  # Oversampling ALTERNATIVO sulle Tipologie   :FACCIO OVERSAMPLING SOLO DELLE SOTTOCLASSI DEBOLI  ( problema: troppo pochi esempi per la classe '3')\n",
        "                                                                   #Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 2\n",
        "  '''\n",
        "  table_count = series_macro_class.value_counts()\n",
        "  table_count = table_count.to_dict()\n",
        "  #print(table_count) \n",
        "  #print(table_count[1])   \n",
        "  #print(type(table_count[1]))  \n",
        "  n_sintetic = 0                                            \n",
        "  oversample = SMOTE({1: table_count[1]+ n_sintetic ,2: table_count[2]+ n_sintetic , 6: table_count[6]+ n_sintetic,\n",
        "                      3: table_count[6]+n_sintetic , 4: table_count[1] +n_sintetic, 5: table_count[2]+n_sintetic}, k_neighbors=1) \n",
        "  data_objs_oversampling, macro_class_oversampling = oversample.fit_resample(dataset_training, series_macro_class)\n",
        "  '''\n",
        "  '''\n",
        "  #PRIMA DELLA FASE DI APPRENDIMENTO DEVO DECODIFICARE LE NUOVE ETICHETTE Y (STATUS:0,1)\n",
        "  #DALL'OVERSAMPLING DELLA MACRO_CLASS DEVO CODIFICARE LE NUOVE ETICHETTE\n",
        "  micro_class = list()\n",
        "  for encoded in macro_class_oversampling: \n",
        "    #print(encoded)\n",
        "    for key, value in encode_tuple.items():  #  in dictionary.iteritems():  (for Python 2.x)\n",
        "      if encoded == value:\n",
        "          #print(key)\n",
        "          micro_class.append(key)\n",
        "  #print(micro_class)\n",
        "  new_df = pd.DataFrame(micro_class, columns=['STATUS', 'Tipologia'])\n",
        "  #print(new_df)\n",
        "  y=new_df['STATUS']\n",
        "  #print(y)\n",
        "  #print(\"Nuova lunghezza del vettore target y (dopo l'oversampling): \", len(y))\n",
        "  return data_objs_oversampling, y\n",
        "  '''\n",
        "  return data_objs_oversampling, macro_class_oversampling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q65EdV_6eYDe",
        "outputId": "89178b20-3b18-4d35-a6fa-4562f51f95e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input = pd.read_csv(\"/content/drive/My Drive/dati/dati_experiment/file2.csv\") #Carico il dataset\n",
        "data_obj = pd.DataFrame(input) #.sample(frac=1)\n",
        "data_obj_droped = data_obj.drop(columns=['PSA', 'ETA','STATUS','Tipologia']) \n",
        "y = data_obj['STATUS']\n",
        "\n",
        "#Standardizzazione dei valori del dataset\n",
        "scaler = StandardScaler(with_std=True)\n",
        "scaler.fit(data_obj_droped) \n",
        "data_objs = scaler.transform(data_obj_droped) \n",
        "data_objs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.31, -0.15,  0.65, ..., -0.92, -0.23,  0.15],\n",
              "       [-0.31, -0.15,  0.65, ..., -0.92, -0.23,  0.15],\n",
              "       [-0.31, -0.15,  0.65, ..., -0.5 , -0.23,  0.15],\n",
              "       ...,\n",
              "       [ 0.54, -0.15,  0.54, ...,  2.27, -0.22, -6.63],\n",
              "       [ 3.05, -0.14,  0.18, ..., -0.91,  3.69,  0.14],\n",
              "       [ 5.69, -0.14, -0.12, ..., -0.9 ,  5.39,  0.14]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sFIZ7Z6beoP"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "batch_size = 32\n",
        "n = data_obj_droped\n",
        "test_predicted_vae = np.zeros((np.array(n).shape[0],)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqAPQhKco_Sy"
      },
      "source": [
        "#Uso Vae per la classificazione senza fare Oversampling (con Smote)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN8yd7fJb4yE",
        "outputId": "f47aad38-391f-43e4-d3c1-6f26b656fda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Uso Vae per la classificazione senza Oversampling \n",
        "dict_model = { \"vae\": {\"accuracy\": [], \"precision\": [], \"recall\": []}, }\n",
        "i = 0\n",
        "\n",
        "ext_fold = 9\n",
        "fold_obj_ext = StratifiedKFold(ext_fold,  True, random_state = 4)  #Stratified 9-fold esterno\n",
        "\n",
        "n_fold = 5\n",
        "fold_obj = StratifiedKFold(n_fold ,  True, random_state = 4)       #Stratified 5-fold interno\n",
        "\n",
        "\n",
        "for train_idx_ext, test_idx_ext in fold_obj_ext.split(data_objs, y): \n",
        "\n",
        "  X_train_ext, X_test = data_objs[train_idx_ext, :], data_objs[test_idx_ext, :]\n",
        "  y_train_ext, y_test = y[train_idx_ext], y[test_idx_ext]\n",
        "  test_Y_one_hot = to_categorical(y_test) #test_labels\n",
        "  indices = np.array(range(len(X_train_ext)))\n",
        "  y_train_ext = np.array(y_train_ext)[indices.astype(int)]\n",
        "\n",
        "  for train_idx, val_idx in fold_obj.split(X_train_ext, y_train_ext): \n",
        "       \n",
        "        i += 1\n",
        "        print(\"Fold: \" + str(i))\n",
        "              \n",
        "        X_train, X_valid = X_train_ext[train_idx, :], X_train_ext[val_idx, :]                  \n",
        "        y_train, y_valid = y_train_ext[train_idx], y_train_ext[val_idx]\n",
        "                                                                                                                                                                                                                                                                #y_valid \n",
        "        vae.fit(X_train, y_train, epochs=200, batch_size=batch_size, shuffle=True, verbose=0, callbacks=[callback], validation_data=(X_valid, y_valid))\n",
        "       \n",
        "        #valid_Y_one_hot = to_categorical(y_valid) #training labels\n",
        "                                        \n",
        "  train_Y_one_hot = to_categorical(y_train) #training labels\n",
        "  \n",
        "    \n",
        "  #In questa fase i layers utilizzati dall‚Äôencoder devono essere prima ‚Äúspenti‚Äù (settati a False). Poi in\n",
        "  #un secondo momento, devono essere ‚Äúriaccesi‚Äù (settati a True), per effettuare l‚Äôapprendimento sulla rete\n",
        "  #Encoder + MPL.\n",
        "            \n",
        "  for layer in full_model.layers[0:2]:\n",
        "\n",
        "    layer.trainable = False  \n",
        "        \n",
        "  full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "  #full_model.summary()\n",
        "        \n",
        "  train_label = train_Y_one_hot\n",
        "  train_X = X_train\n",
        "\n",
        "\n",
        "                        #MLP                                                                            \n",
        "  classify_train = full_model.fit(train_X, train_label, batch_size=32,epochs=200,verbose=0,validation_data=(train_X, train_label))\n",
        "        \n",
        "  for layer in full_model.layers[0:2]:\n",
        "\n",
        "     layer.trainable = True\n",
        "\n",
        "  full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "        \n",
        "  #Ultimo step Train\n",
        "  classify_train = full_model.fit(train_X, train_label, batch_size=batch_size,epochs=200,verbose=0,validation_data=(train_X, train_label))\n",
        "\n",
        "        \n",
        "  test_data = X_test\n",
        "  test_labels = y_test \n",
        "\n",
        "  scores = full_model.evaluate(test_data, test_Y_one_hot, verbose=1)\n",
        "  print('Test loss:', scores[0])\n",
        "  print('Test accuracy:', scores[1])\n",
        "  predicted_classes = full_model.predict(test_data)\n",
        "  predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "  test_predicted_vae[test_idx_ext] = predicted_classes\n",
        "\n",
        "  correct = np.where(predicted_classes==test_labels)[0]\n",
        "  print (\"Found %d correct labels\" % len(correct))\n",
        "\n",
        "  incorrect = np.where(predicted_classes!=test_labels)[0]\n",
        "  print (\"Found %d incorrect labels\" % len(incorrect)) \n",
        "\n",
        "        #classification report\n",
        "  target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
        "  print(classification_report(test_labels, predicted_classes, target_names=target_names))\n",
        "    \n",
        "  print(\"End of kfold\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 1\n",
            "Fold: 2\n",
            "Fold: 3\n",
            "Fold: 4\n",
            "Fold: 5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8000\n",
            "Test loss: 0.2873508632183075\n",
            "Test accuracy: 0.800000011920929\n",
            "Found 4 correct labels\n",
            "Found 1 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      0.67      0.80         3\n",
            "     Class 1       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 6\n",
            "Fold: 7\n",
            "Fold: 8\n",
            "Fold: 9\n",
            "Fold: 10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.8000\n",
            "Test loss: 0.7121333479881287\n",
            "Test accuracy: 0.800000011920929\n",
            "Found 4 correct labels\n",
            "Found 1 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      0.67      0.80         3\n",
            "     Class 1       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 11\n",
            "Fold: 12\n",
            "Fold: 13\n",
            "Fold: 14\n",
            "Fold: 15\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "Test loss: 0.045667994767427444\n",
            "Test accuracy: 1.0\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         3\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 16\n",
            "Fold: 17\n",
            "Fold: 18\n",
            "Fold: 19\n",
            "Fold: 20\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9905 - accuracy: 0.8000\n",
            "Test loss: 0.9905000925064087\n",
            "Test accuracy: 0.800000011920929\n",
            "Found 4 correct labels\n",
            "Found 1 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.75      1.00      0.86         3\n",
            "     Class 1       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.88      0.75      0.76         5\n",
            "weighted avg       0.85      0.80      0.78         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 21\n",
            "Fold: 22\n",
            "Fold: 23\n",
            "Fold: 24\n",
            "Fold: 25\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8727 - accuracy: 0.6000\n",
            "Test loss: 2.8726613521575928\n",
            "Test accuracy: 0.6000000238418579\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01b4acc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 3 correct labels\n",
            "Found 2 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      0.33      0.50         3\n",
            "     Class 1       0.50      1.00      0.67         2\n",
            "\n",
            "    accuracy                           0.60         5\n",
            "   macro avg       0.75      0.67      0.58         5\n",
            "weighted avg       0.80      0.60      0.57         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 26\n",
            "Fold: 27\n",
            "Fold: 28\n",
            "Fold: 29\n",
            "Fold: 30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5229 - accuracy: 0.6000\n",
            "Test loss: 1.5229235887527466\n",
            "Test accuracy: 0.6000000238418579\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01bc9f6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 3 correct labels\n",
            "Found 2 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.50      1.00      0.67         2\n",
            "     Class 1       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.60         5\n",
            "   macro avg       0.75      0.67      0.58         5\n",
            "weighted avg       0.80      0.60      0.57         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 31\n",
            "Fold: 32\n",
            "Fold: 33\n",
            "Fold: 34\n",
            "Fold: 35\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.8000\n",
            "Test loss: 0.22595973312854767\n",
            "Test accuracy: 0.800000011920929\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01b2bf6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 4 correct labels\n",
            "Found 1 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.67      1.00      0.80         2\n",
            "     Class 1       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 36\n",
            "Fold: 37\n",
            "Fold: 38\n",
            "Fold: 39\n",
            "Fold: 40\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 1.0000\n",
            "Test loss: 0.14748422801494598\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01b2886840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 41\n",
            "Fold: 42\n",
            "Fold: 43\n",
            "Fold: 44\n",
            "Fold: 45\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 1.0000\n",
            "Test loss: 0.03010207787156105\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01b24a0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TwBHt5LpJe8"
      },
      "source": [
        "##Uso Vae per la classificazione CON Oversampling (Smote)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOz64PSVpIjW",
        "outputId": "0ce88214-3b4c-496c-f96d-174a320761a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Uso Vae per la classificazione CON Oversampling \n",
        "dict_model = { \"vae\": {\"accuracy\": [], \"precision\": [], \"recall\": []}, }\n",
        "i = 0\n",
        "\n",
        "ext_fold = 9\n",
        "fold_obj_ext = StratifiedKFold(ext_fold,  True, random_state = 4) \n",
        "\n",
        "col_typology = data_obj['Tipologia']   #ci serve per fare l'oversampling sulle tipologie\n",
        "\n",
        "for train_idx_ext, test_idx_ext in fold_obj_ext.split(data_objs, y): \n",
        "\n",
        "  X_train_ext, X_test = data_objs[train_idx_ext, :], data_objs[test_idx_ext, :]\n",
        "  y_train_ext, y_test = y[train_idx_ext], y[test_idx_ext]\n",
        "  test_Y_one_hot = to_categorical(y_test) #test_labels\n",
        " \n",
        "  indices = np.array(range(len(X_train_ext)))\n",
        "  y_train_ext = np.array(y_train_ext)[indices.astype(int)]\n",
        "\n",
        "  \n",
        "  y_tipology = col_typology[train_idx_ext]\n",
        "  y_tipology_ext = np.array(y_tipology)[indices.astype(int)]\n",
        "\n",
        "                                     \n",
        "  for train_idx, val_idx in fold_obj.split(X_train_ext, y_train_ext): \n",
        "        i += 1\n",
        "        print(\"Fold: \" + str(i))\n",
        "        \n",
        "        X_train, X_valid = X_train_ext[train_idx, :], X_train_ext[val_idx, :]\n",
        "                       \n",
        "        y_train, y_valid = y_train_ext[train_idx], y_train_ext[val_idx]\n",
        "\n",
        "        y_tipology_int = y_tipology_ext[train_idx]\n",
        "\n",
        "        X_oversampled, y_oversampled = oversampling_training(X_train, y_train, y_tipology_int) #richiamo la funzione che fa oversampling sul dataset e su y\n",
        "\n",
        "        #print(\"X_train oversampled\", len(X_oversampled))\n",
        "        #print(\"y_train oversampled\", len(y_oversampled))\n",
        "\n",
        "        X_train = X_oversampled\n",
        "        y_train = y_oversampled\n",
        "\n",
        "        print(\"TRAINING oversampled: \", len(X_train))\n",
        "        print(\"Validation sample: \", len(X_valid))\n",
        "                                                                                                                                     \n",
        "        vae.fit(X_train, y_train, epochs=200, batch_size=batch_size, shuffle=True, verbose=0, callbacks=[callback], validation_data=(X_valid, y_valid))\n",
        "         \n",
        "        #valid_Y_one_hot = to_categorical(y_valid) #training labels\n",
        "                                        \n",
        "  train_Y_one_hot = to_categorical(y_train) #training labels\n",
        "\n",
        "  #In questa fase i layers utilizzati dall‚Äôencoder devono essere prima ‚Äúspenti‚Äù (settati a False). Poi in\n",
        "  #un secondo momento, devono essere ‚Äúriaccesi‚Äù (settati a True), per effettuare l‚Äôapprendimento sulla rete\n",
        "  #Encoder + MPL.\n",
        "  for layer in full_model.layers[0:2]:\n",
        "\n",
        "    layer.trainable = False  \n",
        "        \n",
        "  full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "  #full_model.summary()\n",
        "        \n",
        "  train_label = train_Y_one_hot\n",
        "  train_X = X_train\n",
        "\n",
        "                        #MLP                                                                        \n",
        "  classify_train = full_model.fit(train_X, train_label, batch_size=32,epochs=200,verbose=0,validation_data=(train_X, train_label))\n",
        "        \n",
        "  for layer in full_model.layers[0:2]:\n",
        "\n",
        "     layer.trainable = True\n",
        "\n",
        "  full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "        \n",
        "  #Ultimo step Train\n",
        "  classify_train = full_model.fit(train_X, train_label, batch_size=batch_size,epochs=200,verbose=0,validation_data=(train_X, train_label))\n",
        "\n",
        "        \n",
        "  test_data = X_test\n",
        "  test_labels = y_test \n",
        "\n",
        "  scores = full_model.evaluate(test_data, test_Y_one_hot, verbose=1)\n",
        "  print('Test loss:', scores[0])\n",
        "  print('Test accuracy:', scores[1])\n",
        "  predicted_classes = full_model.predict(test_data)\n",
        "  predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "  test_predicted_vae[test_idx_ext] = predicted_classes\n",
        "\n",
        "  correct = np.where(predicted_classes==test_labels)[0]\n",
        "  print (\"Found %d correct labels\" % len(correct))\n",
        "\n",
        "  incorrect = np.where(predicted_classes!=test_labels)[0]\n",
        "  print (\"Found %d incorrect labels\" % len(incorrect)) \n",
        "\n",
        "        #classification report\n",
        "  target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
        "  print(classification_report(test_labels, predicted_classes, target_names=target_names))\n",
        "    \n",
        "  print(\"End of kfold\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold: 1\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    7\n",
            "1    6\n",
            "5    5\n",
            "4    4\n",
            "3    1\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 2\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    10\n",
            "6     7\n",
            "5     5\n",
            "4     4\n",
            "1     4\n",
            "3     2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 3\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    7\n",
            "4    5\n",
            "1    5\n",
            "5    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 4\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    7\n",
            "1    6\n",
            "5    5\n",
            "4    4\n",
            "3    1\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 5\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "6    8\n",
            "2    7\n",
            "1    7\n",
            "5    5\n",
            "4    3\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 1.0000\n",
            "Test loss: 0.10273033380508423\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01c0a05ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         3\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 6\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    8\n",
            "6    6\n",
            "5    6\n",
            "1    6\n",
            "4    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 7\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    7\n",
            "5    5\n",
            "1    5\n",
            "4    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 8\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    8\n",
            "5    6\n",
            "4    6\n",
            "1    5\n",
            "6    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 9\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    8\n",
            "4    6\n",
            "1    6\n",
            "6    5\n",
            "5    5\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 10\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    7\n",
            "6    6\n",
            "5    6\n",
            "1    6\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6550e-04 - accuracy: 1.0000\n",
            "Test loss: 0.0008655036799609661\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01bc7cad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         3\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 11\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "1    8\n",
            "2    7\n",
            "6    6\n",
            "5    6\n",
            "4    4\n",
            "3    1\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 12\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    6\n",
            "5    5\n",
            "4    5\n",
            "1    5\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 13\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    7\n",
            "1    7\n",
            "5    6\n",
            "4    6\n",
            "6    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 14\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    6\n",
            "5    6\n",
            "1    6\n",
            "4    4\n",
            "3    1\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 15\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    8\n",
            "6    6\n",
            "1    6\n",
            "5    5\n",
            "4    5\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Test loss: 0.0015529132215306163\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01a4154048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         3\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 16\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    7\n",
            "5    5\n",
            "1    5\n",
            "4    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 17\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    8\n",
            "6    7\n",
            "5    5\n",
            "1    5\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 18\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    10\n",
            "4     6\n",
            "6     5\n",
            "5     5\n",
            "1     4\n",
            "3     2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 19\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    6\n",
            "4    6\n",
            "1    5\n",
            "5    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 20\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    8\n",
            "6    7\n",
            "5    5\n",
            "1    5\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2063 - accuracy: 0.8000\n",
            "Test loss: 6.206268787384033\n",
            "Test accuracy: 0.800000011920929\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01939c6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 4 correct labels\n",
            "Found 1 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.75      1.00      0.86         3\n",
            "     Class 1       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.88      0.75      0.76         5\n",
            "weighted avg       0.85      0.80      0.78         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 21\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    6\n",
            "5    6\n",
            "1    6\n",
            "4    4\n",
            "3    1\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 22\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    10\n",
            "6     6\n",
            "5     6\n",
            "1     5\n",
            "4     4\n",
            "3     1\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 23\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    6\n",
            "5    6\n",
            "1    5\n",
            "4    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 24\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    11\n",
            "6     7\n",
            "4     5\n",
            "5     4\n",
            "1     3\n",
            "3     2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 25\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    7\n",
            "5    6\n",
            "1    5\n",
            "4    3\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5378 - accuracy: 0.8000\n",
            "Test loss: 2.53784441947937\n",
            "Test accuracy: 0.800000011920929\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01a3d92510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 4 correct labels\n",
            "Found 1 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      0.67      0.80         3\n",
            "     Class 1       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 26\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    7\n",
            "5    5\n",
            "1    5\n",
            "4    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 27\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    11\n",
            "6     7\n",
            "5     5\n",
            "1     4\n",
            "4     3\n",
            "3     2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 28\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    8\n",
            "6    6\n",
            "1    6\n",
            "5    5\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 29\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    8\n",
            "1    7\n",
            "6    6\n",
            "4    5\n",
            "5    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 30\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    8\n",
            "6    6\n",
            "1    6\n",
            "5    5\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 1.0000\n",
            "Test loss: 0.2199706733226776\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01a3a4cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 31\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    9\n",
            "6    6\n",
            "5    5\n",
            "4    5\n",
            "1    5\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 32\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    11\n",
            "6     7\n",
            "5     4\n",
            "4     4\n",
            "1     4\n",
            "3     2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 33\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    8\n",
            "6    6\n",
            "1    6\n",
            "5    5\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 34\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "6    9\n",
            "2    8\n",
            "1    7\n",
            "5    3\n",
            "4    3\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 35\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "6    8\n",
            "2    8\n",
            "1    6\n",
            "4    4\n",
            "5    3\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7489e-04 - accuracy: 1.0000\n",
            "Test loss: 0.000374891038518399\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f019360f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 36\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "6    7\n",
            "2    7\n",
            "1    7\n",
            "4    5\n",
            "5    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 37\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "6    9\n",
            "2    9\n",
            "1    6\n",
            "5    3\n",
            "4    3\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 38\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    9\n",
            "6    5\n",
            "5    5\n",
            "4    5\n",
            "1    5\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 39\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "6    9\n",
            "1    8\n",
            "2    7\n",
            "5    3\n",
            "4    3\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 40\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    8\n",
            "6    6\n",
            "1    6\n",
            "5    5\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Test loss: 0.028372738510370255\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01842d2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n",
            "Fold: 41\n",
            "Numero di Sample per Status:\n",
            "1    16\n",
            "0    16\n",
            "dtype: int64\n",
            "2    8\n",
            "6    6\n",
            "5    6\n",
            "1    6\n",
            "4    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  32\n",
            "Validation sample:  8\n",
            "Fold: 42\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    9\n",
            "1    6\n",
            "6    5\n",
            "5    5\n",
            "4    5\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 43\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    9\n",
            "5    7\n",
            "6    5\n",
            "1    5\n",
            "4    3\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 44\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "1    8\n",
            "6    7\n",
            "2    7\n",
            "5    4\n",
            "4    4\n",
            "3    2\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 45\n",
            "Numero di Sample per Status:\n",
            "0    17\n",
            "1    15\n",
            "dtype: int64\n",
            "2    7\n",
            "1    7\n",
            "5    6\n",
            "6    5\n",
            "4    4\n",
            "3    3\n",
            "dtype: int64\n",
            "TRAINING oversampled:  34\n",
            "Validation sample:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Test loss: 0.0021291181910783052\n",
            "Test accuracy: 1.0\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f018426a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Found 5 correct labels\n",
            "Found 0 incorrect labels\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "End of kfold\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqBwQp0urH_G"
      },
      "source": [
        "'''\n",
        "Funzione per plottare le matrici di confusione\n",
        "'''\n",
        "import itertools\n",
        "#Evaluation of Model - Confusion Matrix Plot\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Reds):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\")\n",
        "                # color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y85JZ7NxrR0i",
        "outputId": "4d5dd0c4-8449-4872-d091-ecc2019c5609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"\\n\\nRisultati metriche VAE: \\n\")\n",
        "\n",
        "print(\"Accuracy VAE: \", accuracy_score(y,test_predicted_vae))\n",
        "print(\"\\nPrecision VAE: \", precision_score(y,test_predicted_vae))\n",
        "print(\"\\nRecall VAE: \", recall_score(y,test_predicted_vae))\n",
        "\n",
        "#VAE\n",
        "dict_model['vae']['accuracy'].append(accuracy_score(y,test_predicted_vae))\n",
        "dict_model['vae']['precision'].append(precision_score(y,test_predicted_vae))\n",
        "dict_model['vae']['recall'].append(recall_score(y,test_predicted_vae))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Risultati metriche VAE: \n",
            "\n",
            "Accuracy VAE:  0.9555555555555556\n",
            "\n",
            "Precision VAE:  0.9545454545454546\n",
            "\n",
            "Recall VAE:  0.9545454545454546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOQIKPNkna1m"
      },
      "source": [
        "#Salvataggio dati (no oversampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W00IwtcunZF7",
        "outputId": "6c1a510b-3f8d-4f5e-d80c-8c0ad1cae997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#SENZA OVERSAMPLING\n",
        "label = [\"vae\"]  \n",
        "dict_pred = {  \"vae\": {\"y_pred\": []},}\n",
        "#Vae\n",
        "dict_pred['vae']['y_pred'].append(test_predicted_vae)\n",
        "\n",
        "for name in label: \n",
        "  y_pred = dict_pred[name]['y_pred']\n",
        "  print(y_pred[0])\n",
        "  cnf_matrix = confusion_matrix(y, y_pred[0])\n",
        "  np.set_printoptions(precision=2)\n",
        "  print(cnf_matrix)\n",
        "  plt.figure()\n",
        "  tit = 'Confusion matrix VAE with StandardScaler -' + name \n",
        "  plot_confusion_matrix(cnf_matrix, classes=['0','1'], title= tit)\n",
        "  plt.savefig('/content/drive/My Drive/dati/test_vae/Plot/mat_conf/' + tit +'.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
            "[[19  4]\n",
            " [ 4 18]]\n",
            "Confusion matrix, without normalization\n",
            "[[19  4]\n",
            " [ 4 18]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAEYCAYAAAAu+iEYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhcVZnv8e/vnASSQBgTvIQpOJAWsQWMTEqMDDYoNjTigECDgDhcB1CviLcfQbpRmtardINDlFykGUVEGUMcLgRsUMI8BFtlDHPCFEJCpvf+sVaRTZFzqk4Np+rU/n3y7CdnT2u/VbXrrbX22oMiAjOzsujrdABmZsPJSc/MSsVJz8xKxUnPzErFSc/MSsVJz8xKpaNJT9JYSZdLel7SxU2Uc4ik2a2MrVMk7S7pT52Oo1Uk3SNp+iDzr5V09DCG1DBJZ0v6lxaW1/bXLulBSXu1cxsjTV1JT9LHJM2V9KKkxyVdLeldLdj+QcDrgI0j4kONFhIR50XEe1sQT1tJCklvHGyZiLg+IqY0UPYsSSevYfr+kp6QNCqPT89xHF+13OQ8/cWq4SNDjaUoIt4SEdfmbZwk6dxmypP0NUkP5NjmS7qoMG/EJNBqktaS9J38ml7Myep7nY6rF9VMepK+CHwP+CYpQW0JfB/YvwXb3wr474hY0YKyRrxKYmrQT4FDJalq+mHAeYX3+HDgGeAfByhng4hYtzBcNMByw07S4aTXs1dErAtMBX7b2ahqU1Lru3YC6fXsBIwHpgO3tjm0ATW5L3a3iBhwANYHXgQ+NMgya5OS4mN5+B6wdp43HZgPfAl4Cngc+Hie9w1gGbA8b+Mo4CTg3ELZk4EARuXxI4D7gUXAA8Ahhek3FNbbDbgZeD7/v1th3rXAPwO/z+XMBiYM8Noq8X+lEP8BwPuA/yYlj68Vlt8JuBF4Li97BrBWnjcnv5bF+fV+pFD+8cATwH9WpuV13pC3sWMenwQ8DUxfQ6xj8+udVpi2IbAUeFseXye/5o/m937qQO91jf3iPcBdhfFfAzcXxq8HDsh/PwjsBexT9Xnf0cDncQbwvQHmnQKszK/3ReCMPP104BHgBeAWYPfCOicBPwPOydu+p+o92YGUeBYBFwEXAv9SeG+vyJ/Hs/nvzav2s1Py61oCvBHYG7gvf05nANcBR+flrwCOHeQ93wL4Rd7ewsLrewPwuzxtAXAe6YeL4vuf/+4Dvgr8NS//M2Cjqs//KOBhYE4d+8E8YL/C+KgcX2V/vZi0Xz9P2v/fUpU3vp239STwQ2BsrW22Yqj1ovYBVjDIFwE4GbgJ2ASYCPwX8M+FpLEiLzOalCxeAjYs7HTFJFc9XvkgRpG+sC8AU/K8TStvIoWkB2yUd8LD8noH5/GNCzvjX4FtSIniWuDUQZLeCuDrOf5P5A/1fNKv8VtIO/TWefm3A7vk7U7OO8WxhfICeOMayv/XvBOMpZD08jKfAO4FxgHXAN8e5LP4MfCTwvgngdsL44eRknE/cDnwH2t6r+vY2ceSksuE/L48CTya35Ox+T2pvN8PsvpL96rPt4HP41DSj8D/ItWK+tdQ1tFrWGfj/Jl8ifQlHFOIZylpv+wHvgXclOetBTwEHJdf40GkhF1JehsDH8yfy3jSF/yXVbE8nPeRUaTvxqJczuhc7gpWJ71/yst/BngroEJZ/cAdwHdJ34MxwLvyvEoyXTtvYw6FH4aq9/8LpO/q5nn5HwEXVH3+5+Rt1ExApO/FeYXx9wPzCuNH5vemUjEq7ovfBS4jfV/Hk/bHb3VD0jsEeKLGMn8F3lcY/zvgwcKXegmFLxKpxrRLg0nvubyjja2K4QhWJ73DgD9Wzb8ROKKwM/5TYd5ngFkDvLZK/P15fHyOZ+fCMreQazVrWP9Y4NLC+JqS3jLyl7AwbX5VOZcBdwF3kmvRA2zvXfk9qnypfw8cV5j/G/IXgvRj8DQwuuq9fq5qePMA27oeOJCU5GeTag37kGqBdw7wpXvV5zvUz6OwT/6GVGNeCBxfVdbRA62bl3mW1TXfk4DfFOZtCyzJf08jtVyKyee/yElvDeVuDzxbFcvJhfF/JCfUPC5SLb+S9PqB/5k/s5fztg/P83bNn1U9P0gHALcN8P7PA/YszNuUlMgrP9IBvL7WNgrrv5GUyMfl8fOArw+w7Aa5/PXza18MvKEwf1fggXq33cxQ6zjDQmBCjfb9JNIvYsVDedorZcSrj9m9BKxbY7uvERGLSU3CTwGPS7pS0t/UEU8lps0K408MIZ6FEbEy/70k//9kYf6SyvqStpF0Re44eIF0HHTCIGUDPB0RS2ss82NgO1LN7OWBFoqIG0hNnAMkvYHU3D4/x7YFKSGdlxf/FanG8P6qYiZExAaFYd4Am7uOlKCn5b+vBd6dh+tqvJ5qdX8ekTqt9iJ9iT4F/LOkvxtoeUlfljQvnyHwHOlLV/xMqrc9Ju/vk4BHI38js1f2K0njJP1I0kP5s54DbCCpv7D8I4W/JxXHc7nF8ZURcWZEvDO/tlOAmZLeTGraPhRrOPYt6XWSLpT0aI7jXAbe57YCLpX0XH4v5pEOCbxugJirt3V1oYPrkIj4Sy7jA5LGAX/P6v2tX9Kpkv6a43owFzOBVCMdB9xSiGVWnt52tZLejaRfnQMGWeYx0ptZsWWe1ojFpDej4n8UZ0bENRGxN+kX6j5SMqgVTyWmRxuMaSh+QIrrTRGxHvA10q/aYGKwmZLWJTUNzgJOkrRRjfLOIdUqDgWuiYhKgj6M9HlfLukJ0rHRMaSOjUZUJ73rqJ30Bn2tQxERyyPiYlLtd7s1lS9pd9Lx2A+TDqlsQDq+VOszgXQYYLOqjqEtC39/CZhCqvWvR3ofqCq7GM/jpORViU3F8arXtiQiziTVSrclJaItB6h8fDNv5605jkMZ+PU9Auxb9aM2JiKK340BP6OI2DdWd3BVfjwvILUa9gfuzYkQ4GN52l6kH5rJlZdO+mFeQjo8VYlj/UidU203aNKLiOdJ7fYzJR2Qf91GS9pX0ml5sQuAf5I0UdKEvHyjpyXcDkyTtKWk9Uk9WsArv2j7S1qHlIhfBFatoYyrgG3yaTaj8ikX25IOFLfbeNJxxxdzLfTTVfOfBF4/xDJPB+ZGxNHAlaQDvoM5h7SjfYLUo1txOKnzaPvC8EHgfZI2HmJMkJp6U0i1yT9GxD2kH5udSbWeNXkSmFxHT+YaSTpC0vsljZfUJ2lf0jGzPxTKL76/40nHzZ4GRkn6OrBenZu7Ma/7+bzPH0h6rcWylwDP5R+iE2uUdyXwFkkH5uT1eQo/6pKOzacTjc377eF5G7cBfyQlzVMlrSNpjKR3FuJ4EXhe0mak450D+SFwiqSt8jYnSmr2LIwLgfeS9vXzC9PHk76nC0kVmW9WZkTEKlKF5buSNsmxbDZYjb2Vau58EfEd4IukA61Pk34tPgv8Mi/yL8Bc0i/uXaTeroZO4IyIX5N6ye4kHSsrJqq+HMdjpIPZ7+a1SYWIWAjsR/olXkj6pd8vIhY0EtMQfZn0C7eI9KFWn+5xEvDTXKX/cK3C8g65D6tf5xeBHSUdMtA6EfEgKSGtQzoWiKRdSAnpzIh4ojBcBvyF9Etd8VzVeXpfHGA7i0mf9T0RsSxPvpHUDHtqgPAqJ6AvlNTI6RgvkGrPD5OON54GfDo36yH9QBwk6VlJ/07q+JlF6ml/iNRpMWDzrSi/pgNJx4ufIR1a+UVhke+ROl4WkDoHZtUobwHwIeBU0n75JtLxu4qXgO+QmtsLSMf3PhgR9+fDKx8gHUN7mHQssHL+5DeAHUk12CurYqx2OmmfmC1pUY5758HiriUiHid97rvx6v39HNJ7/iipI+6mqlWPJ+17N+Xm729IP6Jtp1cfsjAz622+9tbMSsVJz8xKxUnPzErFSc/MSmVEXFQ8Rorxzs8jylY7/G2nQ7AhuuW22xdERMtOEN5Co2JpnadmLmDVNRGxT6u2PZgRkfTG08cHX3XOsnW7H95wbadDsCHSOhtUX8nUlKUEH2Sdupb9EYtqXbnUMiMi6ZnZyCO68/iZk56ZtYWAUa+5veMAhvF0YSc9M2ubvjpznpOemfUEN2/NrDSE6Ku3eTuMnPTMrG1c0zOz0hBDOKY3jJz0zKw9BP1u3ppZWfg8PTMrnW5s3nZjIjazHtFX51CLpJmSnpJ0d2Ha9pJuknS7pLmSdhqsjGJMZmYtlzoyVNdQh7NJj04oOg34RkRsT3o2z2nVK62Jm7dm1jatqlVFxBxJk6sns/pBT+tT51MYnfTMrC3Stbd1Lz5B0tzC+IyImFFjnWOBayR9m5Rfd6tnQ056ZtY2fXU9YhiABRExdYjFfxo4LiIuyU8XPIv0+NMaMZmZtUHl5OR6hgYdzupHXl7Mq59LPCAnPTNrm1b13g7gMdLzrwH2AP5cz0pu3ppZW6i5WlxVWboAmE469jcfOBH4BHC6pFGkB7kfU09ZTnpm1jZ130S0hog4eIBZbx9qWU56ZtYWvgzNzEqnGy9Dc9Izs7YQGsopK8PGSc/M2sY1PTMrlS7MeU56ZtYeQ3oE5DBy0jOztmjleXqt5KRnZm3jU1bMrFS6sKLnpGdm7VG5iWi3cdIzs7bpvpTnpGdmbeRjemZWKnLz1szKQrh5a2Yl4+atmZVKF7ZunfTMrD3S/fS6L+s56ZlZ23RfynPSM7M28rW3ZlYiQl1Y1+vGzhUz6wEawlCzLGmmpKck3V01/XOS7pN0j6TT6onLNT0zaw+1tPf2bOAM4JxXipfeA+wPvC0iXpa0ST0FOemZWdv0t6h5GxFzJE2umvxp4NSIeDkv81Q9Zbl5a2ZtMcTm7QRJcwtDPQ/u3gbYXdIfJF0n6R31xOWanpm1zRCatwsiYuoQix8FbATsArwD+Jmk10dEDLaSa3pm1jat6sgYwHzgF5H8EVgFTKi1kpOembWN6vzXoF8C7wGQtA2wFrCg1kpu3g6Ta1nKQ6xkLOLDjANgISuZw8usANZF7MkY1urC85pstZUrVzL1XdPZbNIkrrjkok6H09XSnZNbVJZ0ATCddOxvPnAiMBOYmU9jWQYcXqtpC056w2YbRvMWRvP/ePmVadfxMruwNpPo5z6WcwfLeAdrdzBKq+X0M3/Am6dM4YVFizodyojQqqZkRBw8wKxDh1qWm7fDZBL9jKmqxT3PKjbNH8Hm9HM/KzoRmtVp/qOPcuWs2Rx9xGGdDmXEaHPztiFOeh20IX08yEoA7mcFi6lZM7cOOvYrJ3DaKSfT1+evTb2k+obh1JFPT9I+kv4k6S+SvtqJGLrBuxnDvSznEl5iGf4F6mZXXD2LTSZO5O07bN/pUEaMdGup+obhNOzH9CT1A2cCe5O6nG+WdFlE3DvcsXTahvTxfsYC8ByreNjN2671+xv/wGVXXs1V18xm6dKXeWHRIg498hjOnTmj06F1tW7slutE5WIn4C8RcX9ELAMuJF0/VzpLWAVAENzKMrZldIcjsoF86+QTmf/ne3lw3l1c+NOz2OPd05zw6iCprmE4daL3djPgkcL4fGDn6oXyZSjHQDqdY6T7DUt5nJUsJTiXxUxlLZYT3MNyALZmFFPcmW49pNK87TZd+y2LiBnADICJ6h/xR/j3Yswap7+VtYY5EmvW9Gm7M33a7p0Oo/t1oBZXj04kvUeBLQrjm+dpZtZjfOfk5GbgTZK2JiW7jwIf60AcZtZm6sKsN+xJLyJWSPoscA3QD8yMiHuGOw4zay/hR0C+IiKuAq7qxLbNbJgI+lzTM7MycU3PzErFvbdmVho+pmdm5SLo68Ks56RnZm3ThTnPSc/M2kOIvv7uy3pOembWHnJHhpmVTBfmPCc9M2ufbqzpdeOdX8ysR7TqdvGSZkp6Kj/5rHrelySFpJrPvAUnPTNrk/QISNU11OFsYJ/XbEPaAngv8HC9cTnpmVl75Gtv6xlqiYg5wDNrmPVd4CtQ/1O1fEzPzNpmCIf0JkiaWxifkW8kPEjZ2h94NCLuGMqxQyc9M2uLIV6GtiAiptZdtjQO+BqpaTskTnpm1h5SO28i+gZga6BSy9scuFXSThHxxGArOumZWdu064yViLgL2GT1dvQgMDUiFtRa1x0ZZtYWAvr7VNdQsyzpAuBGYIqk+ZKOajQu1/TMrG1adXJyRBxcY/7kesty0jOz9qjzxOPh5qRnZm3TjZehOemZWdt0Yc5z0jOz9kjn6XVf1nPSM7P2kG8iamZl4+femlmpuHlrZqXRS7eLl/QfDHIrl4j4fMMRmVnv6KHm7dzai5hZuXXn2ckNJb2I+GlxXNK4iHipNSGZWS+QQP3dd3l/UxFJ2lXSvcB9efxtkr7fksjMbMRTn+oahlOzafh7wN8BCwEi4g5gWrNBmVmPaNWTgVqo6d7biHikqodmZbNlmlkPkHqqI6PiEUm7ASFpNPAFYF7zYZlZL+iZU1YKPgWcDmwGPAZcA/zPZoMysx6Q7iLa6Sheo6mkl2/NfEiLYjGzHqPuy3lN996+XtLlkp7OTx//laTXtyo4MxvhurAjo9k8fD7wM2BTYBJwMXBBs0GZWQ9QfaerjLRTVsZFxH9GxIo8nAuMaUVgZtYDeqWmJ2kjSRsBV0v6qqTJkraS9BXgqtaGaGYjVp/qG2qQNDMfQru7MO3fJN0n6U5Jl0raoJ6QGu3IuIV0w4FKtJ8szAvghAbLNbMe0eLL0M4GzgDOKUz7NXBCRKyQ9K+kvHN8rYIavfZ260bWM7MyaV3TNSLmSJpcNW12YfQm4KB6ymr6igxJ2wHbUjiWFxHnDLyGmZXFEE5OniCpePemGRExYwibOhK4qJ4Fm0p6kk4EppOS3lXAvsANvLoKamZlJIZyGdqCiJja0Gak/w2sAM6rZ/lmG9wHAXsCT0TEx4G3Aes3WaaZ9QhJdQ1NlH8EsB9wSEQMeGPjomabt0siYpWkFZLWA54CtmiyTDPrFW08B0/SPsBXgHcP5X6ezSa9ubmb+MekHt0XgRubLNPMeoHUst5bSReQDqVNkDQfOJHUW7s28OtcW7wpIj5Vq6xmr739TP7zh5JmAetFxJ3NlGlmPaR1vbcHr2HyWY2U1eiDgXYcbF5E3NpIuWbWQ4bWkTFsGq3pfWeQeQHs0WC5a7TVDn/LD2+4tpVFWpv968Y+ldN66H56EfGeVgdiZr2mN++cbGY2sF6p6ZmZ1SSgr/vuIuqkZ2Ztoq5Mes3eOVmSDpX09Ty+paSdWhOamY14vXI/vYLvA7sClXNoFgFnNlmmmfUC0ZVJr9nm7c4RsaOk2wAi4llJa7UgLjPrBT3YkbFcUj/p3DwkTQRWNR2VmfUAQX9/p4N4jWabt/8OXApsIukU0m2lvtl0VGY28vVi8zYizpN0C+n2UgIOiIh5LYnMzEa+XmveStoSeAm4vDgtIh5uNjAzG+m685SVZo/pXcnqBwSNAbYG/gS8pclyzawX9FpNLyLeWhzPd1/5zACLm1mZVI7pdZmWXpEREbdK2rmVZZrZyCSEurD3ttljel8sjPYBOwKPNRWRmfWOHqzpjS/8vYJ0jO+SJss0s17Qa83bfFLy+Ij4cgvjMbNe0itJT9KoiFgh6Z2tDsjMekVvnbLyR9Lxu9slXQZcDCyuzIyIX7QgNjMb6VpU05M0k/R826ciYrs8bSPgImAy8CDw4Yh4tlZZzabhMcBC0jMx9gM+kP83s7Kr3ES0nqG2s4F9qqZ9FfhtRLwJ+G0er6nRmt4muef2blafnFxR11PGzazXta55GxFzJE2umrw/6Vm4AD8FrgWOr1VWo0mvH1iXVye7V+JrsEwz6zX1N28nSJpbGJ8RETNqrPO6iHg8//0E8Lp6NtRo0ns8Ik5ucF0zK4OhnbKyICKmNrqpiAhJdVW4Gk163dcPbWZdpu29t09K2jQiHpe0KfBUPSs1GtGeDa5nZmXSuo6MNbkMODz/fTjwq7pCamRLEfFMI+uZWYm08Caiki4AbgSmSJov6SjgVGBvSX8G9srjNfkRkGbWJi3tvT14gFlDbnU66ZlZ+/TKZWhmZnVx0jOz0hCg3rn21syshu58BKSTnpm1j5u3ZlYa6q1bS5mZ1eaanpmVijsyzKxUXNMzs9KQe2/NrGzcvDWz0pCgz81bMysT1/TMrFTckWFm5SHX9MysRAT0O+mZWZm4pmdmpeHeWzMrHdf0zKxU3HtrRStXrmTqu6az2aRJXHHJRZ0Ox6pcvHwx961czroSx629PgCPrVrBpctfYgXpUYIHjB7HFn3+Gq1Riy9Dk3QccDQQwF3AxyNi6VDL6b66Z4mcfuYPePOUKZ0Owwbw9v61OHKtdV817eoVS9hr1Fi+sPZ67D1qLFctX9Kh6EYI9dU31CpG2gz4PDA1IrYD+oGPNhKSk16HzH/0Ua6cNZujjzis06HYAF7fN5qxvLZ5tpR45f/1urD51lVa9NzbbBQwVtIoYBzwWCMhuV7eIcd+5QROO+VkFi1a1OlQbAg+MGocZy1bxFXLXyKAT689vtMhdbEh3Tl5gqS5hfEZETGjMhIRj0r6NvAwsASYHRGzG4mqIzU9STMlPSXp7k5sv9OuuHoWm0ycyNt32L7TodgQ3bTyZfYbPY4TxmzAfqPHccnylzodUvcSQ6npLYiIqYVhxquKkjYE9ge2BiYB60g6tJGwOtW8PRvYp0Pb7rjf3/gHLrvyaia/+a189PCj+N11czj0yGM6HZbV4ZaVL7Nd32gA3to3mkdWrehwRF2uRcf0gL2AByLi6YhYDvwC2K2RkDqS9CJiDvBMJ7bdDb518onM//O9PDjvLi786Vns8e5pnDtzRu0VrePWUx/350T311UrmKDuu0lm98i9t/UMtT0M7CJpnCQBewLzGomqa4/pSToGOAZgyy226HA0VkYXLHuR+1etYDHBN5c+x96jxvLB0etw+fKXWLliCaOBfxg9rtNhdq9K87YFIuIPkn4O3AqsAG4DGqopdG3Sy236GQBTd9whOhxO20yftjvTp+3e6TBsDQ6uOl2l4nNrrzfMkYxUrb3LSkScCJzYbDldm/TMrAd04Sk9Tnpm1j5deO1tp05ZuQC4EZgiab6kozoRh5m1UeUuK/UMw6gjNb2IOLgT2zWzYdbXfb3bbt6aWZv4dvFmVjJyR4aZlYZwTc/MysTNWzMrmxbeRLRVnPTMrD1aeBlaKznpmVmbuHlrZmXjmp6ZlYpremZWGn7Yt5mVji9DM7PycEeGmZWNOzLMrDR8GZqZlcuQnns7bJz0zKxtuvEuK92Xhs2sN4jUe1vPUE9x0gaSfi7pPknzJO3aSFiu6ZlZm7S89/Z0YFZEHCRpLaCh52866ZlZ+7SoeStpfWAacARARCwDljVSlpu3ZtY+fX31DTBB0tzCcExVSVsDTwP/V9Jtkn4iaZ2GQmryJZmZrZlU/wALImJqYZhRVdooYEfgBxGxA7AY+GojYTnpmVn7tK4jYz4wPyL+kMd/TkqCQw+pkZXMzOqjOofBRcQTwCOSpuRJewL3NhKROzLMrE3Uso6M7HPAebnn9n7g440U4qRnZu3TwqQXEbcDU5stx0nPzNqo+67IcNIzs/bwg4HMrHSc9MysPFrekdESTnpm1j5OemZWLk56ZlYmrumZWbk46ZlZWci3izez0nFNz8xKpBufkeGkZ2bt46RnZuVR322jhpuTnpm1j2t6ZlYaotVPQ2sJJz0zax/X9MysVLov5znpmVm7uCPDzMrGzVszK40u7cjovojMrHfU/7DvOotTv6TbJF3RaEiu6ZlZm7TlzslfAOYB6zVagGt6ZtZGrXnYN4CkzYH3Az9pKqKIaGb9YSHpaeChTsfRJhOABZ0OwurWy5/XVhExsVWFSZpFer/qMQZYWhifEREzqsr7OfAtYDzw5YjYr5G4RkTztpUfRLeRNDcimn6AsQ0Pf171i4h9WlWWpP2ApyLiFknTmynLzVszGwneCfy9pAeBC4E9JJ3bSEFOembW9SLihIjYPCImAx8FfhcRhzZSlpNe582ovYh1EX9eI9yI6MgwM2sV1/TMrFSc9MysVJz0zKxUnPSGmaQpknaVNFpSf6fjsfr4s+od7sgYRpIOBL4JPJqHucDZEfFCRwOzAUnaJiL+O//dHxErOx2TNcc1vWEiaTTwEeCoiNgT+BWwBXC8pIYvnrb2yVcB3C7pfICIWOka38jnpDe81gPelP++FLgCGA18TN34VOQSk7QO8FngWGBZ5ex/J76Rz0lvmETEcuD/AAdK2j0iVgE3ALcD7+pocPYaEbEYOBI4H/gyMKaY+DoZmzXHSW94XQ/MBg6TNC0iVkbE+cAk4G2dDc2qRcRjEfFiRCwAPgmMrSQ+STtK+pvORmiNGBF3WekVEbFU0nlAACfkL83LwOuAxzsanA0qIhZK+iTwb5LuA/qB93Q4LGuAk94wi4hnJf0YuJdUe1gKHBoRT3Y2MqslIhZIuhPYF9g7IuZ3OiYbOp+y0kH5gHjk43vW5SRtCPwM+FJE3NnpeKwxTnpmQyBpTEQsrb2kdSsnPTMrFffemlmpOOmZWak46ZlZqTjpmVmpOOn1CEkrJd0u6W5JF0sa10RZZ0s6KP/9E0nbDrLsdEm7NbCNByW95pmoA02vWubFIW7rJElfHmqM1puc9HrHkojYPiK2A5YBnyrOlNTQiegRcXRE3DvIItOBISc9s05x0utN1wNvzLWw6yVdBtwrqV/Sv0m6WdKd+bIqlJwh6U+SfgNsUilI0rWSpua/95F0q6Q7JP1W0mRScj0u1zJ3lzRR0iV5GzdLemded2NJsyXdI+knQM27ykj6paRb8jrHVM37bp7+W0kT87Q3SJqV17ne18bamvgytB6Ta3T7ArPypB2B7SLigZw4no+Id0haG/i9pNnADsAUYFvSdcD3AjOryp0I/BiYlsvaKCKekfRD4MWI+HZe7nzguxFxg6QtgWuANwMnAjdExMmS3g8cVcfLOTJvYyxws6RLImIhsA4wNyKOk/T1XPZnSY9n/FRE/FnSzsD3gT0aeButhznp9Y6xkm7Pf18PnEVqdv4xIh7I098L/G3leB2wPun+ftOAC/Itkx6T9Ls1lL8LMKdSVkQ8M0AcewHbFm4PuBd6qIYAAAFhSURBVJ6kdfM2DszrXinp2Tpe0+cl/UP+e4sc60JgFXBRnn4u8Iu8jd2AiwvbXruObVjJOOn1jiURsX1xQv7yLy5OAj4XEddULfe+FsbRB+xSfanWUO+RKmk6KYHuGhEvSboWGDPA4pG3+1z1e2BWzcf0yuUa4NP51vVI2ibfIXgO8JF8zG9T1nzLpJuAaZK2zutulKcvAsYXlpsNfK4yIqmShOYAH8vT9gU2rBHr+sCzOeH9DammWdEHVGqrHyM1m18AHpD0obwNSfI9Cu01nPTK5Sek43W3Srob+BGptn8p8Oc87xzgxuoVI+Jp4BhSU/IOVjcvLwf+odKRAXwemJo7Su5ldS/yN0hJ8x5SM/fhGrHOAkZJmgecSkq6FYuBnfJr2AM4OU8/BDgqx3cPsH8d74mVjG84YGal4pqemZWKk56ZlYqTnpmVipOemZWKk56ZlYqTnpmVipOemZXK/wfpAoM6myoypgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mq6N2dqmP_6"
      },
      "source": [
        "#SALVO I DATI DELLE METRICHE (senza oversampling)\n",
        "for key in dict_model.keys():   \n",
        "    np.save('/content/drive/My Drive/dati/test_vae/StandardScaler/accuracy_'+ str(key) , list(dict_model[key]['accuracy']))\n",
        "    np.save('/content/drive/My Drive/dati/test_vae/StandardScaler/precision_'+ str(key) , list(dict_model[key]['precision']))\n",
        "    np.save('/content/drive/My Drive/dati/test_vae/StandardScaler/recall_'+ str(key) , list(dict_model[key]['recall']))\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS1XYAnvnNnL"
      },
      "source": [
        "#Salvataggio dati (si oversampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIQS3tWinDVc",
        "outputId": "54fbaa6b-ddaf-4332-b4e3-466f2ba9327b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#CON OVERSAMPLING\n",
        "label = [\"vae\"]  \n",
        "dict_pred = {  \"vae\": {\"y_pred\": []},}\n",
        "#Vae\n",
        "dict_pred['vae']['y_pred'].append(test_predicted_vae)\n",
        "\n",
        "for name in label: \n",
        "  y_pred = dict_pred[name]['y_pred']\n",
        "  print(y_pred[0])\n",
        "  cnf_matrix = confusion_matrix(y, y_pred[0])\n",
        "  np.set_printoptions(precision=2)\n",
        "  print(cnf_matrix)\n",
        "  plt.figure()\n",
        "  tit = 'Confusion matrix with StandardScaler and Oversampling -' + name \n",
        "  plot_confusion_matrix(cnf_matrix, classes=['0','1'], title= tit)\n",
        "  #plt.savefig('/content/drive/My Drive/dati/test_vae/Plot/mat_conf/' + tit +'.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
            "[[22  1]\n",
            " [ 1 21]]\n",
            "Confusion matrix, without normalization\n",
            "[[22  1]\n",
            " [ 1 21]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyGztgCtmlOB"
      },
      "source": [
        "#SALVO I DATI DELLE METRICHE (CON oversampling)\n",
        "for key in dict_model.keys():   \n",
        "    np.save('/content/drive/My Drive/dati/test_vae/StandardScaler/accuracy_'+ str(key) + '_oversampling', list(dict_model[key]['accuracy']))\n",
        "    np.save('/content/drive/My Drive/dati/test_vae/StandardScaler/precision_'+ str(key) + '_oversampling', list(dict_model[key]['precision']))\n",
        "    np.save('/content/drive/My Drive/dati/test_vae/StandardScaler/recall_'+ str(key) + '_oversampling', list(dict_model[key]['recall']))\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ravBDtrJyI4K"
      },
      "source": [
        "#PLOT di comparazione tra metriche (con e senza uso di oversampling nella classificazione con VAE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOVHzMuIyUpi",
        "outputId": "bcbbfdb6-e881-4061-8879-4d460a134e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "source": [
        "item_accuracy, item_precision, item_recall = [] , [] , []\n",
        "labels = ['Vae', 'Vae_SMOTE']\n",
        "temp = []\n",
        "\n",
        "value_acc = np.load('/content/drive/My Drive/dati/test_vae/StandardScaler/accuracy_'+ str(label[0]) + '.npy', allow_pickle=True)\n",
        "for v in value_acc: \n",
        "  temp.append(v)\n",
        "item_accuracy.append(tuple(temp)[0])\n",
        "temp.clear()\n",
        "del value_acc\n",
        "value_acc = np.load('/content/drive/My Drive/dati/test_vae/StandardScaler/accuracy_'+ str(label[0]) + '_oversampling.npy', allow_pickle=True)\n",
        "for v in value_acc: \n",
        "  temp.append(v)\n",
        "item_accuracy.append(tuple(temp)[0])\n",
        "temp.clear()\n",
        "\n",
        "value_pre = np.load('/content/drive/My Drive/dati/test_vae/StandardScaler/precision_'+ str(label[0]) + '.npy', allow_pickle=True)\n",
        "for v in value_pre: \n",
        "   temp.append(v)\n",
        "item_precision.append(tuple(temp)[0])\n",
        "temp.clear()\n",
        "del value_pre\n",
        "value_pre = np.load('/content/drive/My Drive/dati/test_vae/StandardScaler/precision_'+ str(label[0]) + '_oversampling.npy', allow_pickle=True)\n",
        "for v in value_pre: \n",
        "   temp.append(v)\n",
        "item_precision.append(tuple(temp)[0])\n",
        "temp.clear()\n",
        "\n",
        "value_rec = np.load('/content/drive/My Drive/dati/test_vae/StandardScaler/recall_'+ str(label[0]) + '.npy', allow_pickle=True)\n",
        "for v in value_rec: \n",
        "  temp.append(v)\n",
        "item_recall.append(tuple(temp)[0])\n",
        "temp.clear()\n",
        "del value_rec\n",
        "value_rec = np.load('/content/drive/My Drive/dati/test_vae/StandardScaler/recall_'+ str(label[0]) + '_oversampling.npy', allow_pickle=True)\n",
        "for v in value_rec: \n",
        "  temp.append(v)\n",
        "item_recall.append(tuple(temp)[0])\n",
        "temp.clear()\n",
        "\n",
        "item_recall = pd.Series(item_recall)\n",
        "print(item_recall)\n",
        "\n",
        "\n",
        "print(item_precision)\n",
        "item_precision = pd.Series(item_precision)\n",
        "print(item_precision)\n",
        "\n",
        "item_accuracy = pd.Series(item_accuracy)\n",
        "print(item_accuracy)\n",
        "\n",
        "df = pd.DataFrame({'accuracy':item_accuracy,'precision': item_precision, 'recall': item_recall, 'Model': labels})\n",
        "title = \"Classification on Data Radiomic with VAE\"\n",
        "plot = df.plot(x= 'Model', kind='bar', legend=True, title = title)\n",
        "fig = plot.get_figure()\n",
        "\n",
        "fig.savefig('/content/drive/My Drive/dati/test_vae/Plot/' + title + '.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.818182\n",
            "1    0.954545\n",
            "dtype: float64\n",
            "[0.8181818181818182, 0.9545454545454546]\n",
            "0    0.818182\n",
            "1    0.954545\n",
            "dtype: float64\n",
            "0    0.822222\n",
            "1    0.955556\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}